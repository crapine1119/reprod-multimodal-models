defaults:
  - hf_config: base
  - module: lit_module
  - datamodule: lit_datamodule
  - _self_

hydra:
  run:
    dir: ${project_root}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: false

project_root: ${hydra:runtime.cwd}
seed: 42

logger:
  _target_: lightning.pytorch.loggers.TensorBoardLogger
  save_dir: ${hydra:run.dir}

callbacks:
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: valid/loss
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${hydra:run.dir}/checkpoints
    filename: "epoch={epoch:03d}-step={step}-val_loss={valid/loss:.4f}"
    monitor: valid/loss
    mode: min
    save_top_k: 3
    save_last: true
    every_n_epochs: 1
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch

trainer:
  _target_: lightning.Trainer
  max_epochs: 20
  accelerator: mps
  devices: 1
  precision: bf16-mixed
  log_every_n_steps: 10
  enable_checkpointing: true
  default_root_dir: ${hydra:run.dir}
  logger: ${..logger}
  callbacks: ${..callbacks}
